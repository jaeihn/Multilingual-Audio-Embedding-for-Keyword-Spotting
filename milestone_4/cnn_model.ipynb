{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import WhisperForAudioClassification, WhisperConfig\n",
    "import torch\n",
    "import evaluate\n",
    "import librosa\n",
    "import wandb\n",
    "from torch.utils.data import DataLoader\n",
    "from datasets import load_dataset\n",
    "from datasets import Dataset\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KWS_dataset(Dataset):\n",
    "    def __init__(self, input_data, output_data):\n",
    "        self.input_data = input_data\n",
    "        self.output_data = output_data\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.input_data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        keyword = self.output_data[index]\n",
    "        audio_features = self.input_data[index]\n",
    "        return audio_features, keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/\"\n",
    "train_dataloader = torch.load('../data/en_splits_30.trainloader')\n",
    "dev_dataloader = torch.load('../data/en_splits_30.devloader')\n",
    "test_dataloader = torch.load('../data/en_splits_30.testloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26411\n",
      "3284\n",
      "3304\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataloader.dataset))\n",
    "print(len(dev_dataloader.dataset))\n",
    "print(len(test_dataloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "\n",
    "class EfficientNetModel(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(EfficientNetModel, self).__init__()\n",
    "        # Load EfficientNet-B0 as the base model\n",
    "        self.efficient_b0_model = torchvision.models.efficientnet_b0(pretrained=True)\n",
    "\n",
    "        # Add a global average pooling layer\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d((None, 512))\n",
    "\n",
    "        # Add two dense layers of 2048 units with ReLU activations\n",
    "        self.linear1 = nn.Linear(512, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(512, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        # Add a penultimate 1024-unit SELU activation layer\n",
    "        self.linear3 = nn.Linear(512, 256)\n",
    "        self.selu = nn.SELU()\n",
    "        # add a softmax layer\n",
    "        self.linear4 = nn.Linear(256, num_classes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(f\"input shape: {x.shape}\")\n",
    "        # Pass the input through the base model\n",
    "        x = x.unsqueeze(1)\n",
    "        # print(f\"after unsqueeze: {x.shape}\")\n",
    "        x = x.repeat(1, 3, 1, 1)\n",
    "        # print(f\"after repeat: {x.shape}\")\n",
    "        x = self.efficient_b0_model(x)\n",
    "        # print(f\"after efficientnet: {x.shape}\")\n",
    "        # add a 1 to the first dimension\n",
    "        x = x.unsqueeze(0)\n",
    "        # print(f\"after unsqueeze: {x.shape}\")\n",
    "        # Pass the output through the global average pooling layer\n",
    "        x = self.global_avg_pool(x)\n",
    "        # print(f\"after global_avg_pool: {x.shape}\")\n",
    "        # pass the output through the dense layers\n",
    "        # remove the first 1 in the shape\n",
    "        x = x.squeeze(0)\n",
    "        # print(f\"after squeeze: {x.shape}\")\n",
    "        x = self.linear1(x)\n",
    "        # print(f\"after linear1: {x.shape}\")\n",
    "        x = self.relu1(x)\n",
    "        # print(f\"after relu1: {x.shape}\")\n",
    "        x = self.linear2(x)\n",
    "        # print(f\"after linear2: {x.shape}\")\n",
    "        x = self.relu2(x)\n",
    "        # print(f\"after relu2: {x.shape}\")\n",
    "        x = self.linear3(x)\n",
    "        # print(f\"after linear3: {x.shape}\")\n",
    "        x = self.selu(x)\n",
    "        # print(f\"after selu: {x.shape}\")\n",
    "        # pass the output through the softmax layer\n",
    "        x  = self.linear4(x)\n",
    "        # print(f\"after linear4: {x.shape}\")\n",
    "        x = self.softmax(x)\n",
    "        # print(f\"after softmax: {x.shape}\")\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "metric = evaluate.load(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = EfficientNetModel(31)\n",
    "model.to(device)\n",
    "optim = torch.optim.Adam(model.parameters())\n",
    "loss_fn = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:4rqyg4oq) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fe9c8337f2f4599abcbdcd0af8ffcc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-fire-4</strong> at: <a href='https://wandb.ai/the-wild-bunch/efficientnet/runs/4rqyg4oq' target=\"_blank\">https://wandb.ai/the-wild-bunch/efficientnet/runs/4rqyg4oq</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20230427_122633-4rqyg4oq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:4rqyg4oq). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.0 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.14.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/jaeihn/projects/MDS-CL/COLX_585_The-Wild-Bunch/milestone_4/wandb/run-20230427_132824-lsup8dv3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/the-wild-bunch/efficientnet/runs/lsup8dv3' target=\"_blank\">robust-universe-5</a></strong> to <a href='https://wandb.ai/the-wild-bunch/efficientnet' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/the-wild-bunch/efficientnet' target=\"_blank\">https://wandb.ai/the-wild-bunch/efficientnet</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/the-wild-bunch/efficientnet/runs/lsup8dv3' target=\"_blank\">https://wandb.ai/the-wild-bunch/efficientnet/runs/lsup8dv3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 3302/3302 [1:37:16<00:00,  1.77s/it]\n",
      "100%|███████████████████████████████████████████| 13/13 [01:06<00:00,  5.14s/it]\n",
      " 44%|████████████████                     | 1438/3302 [48:57<1:04:38,  2.08s/it]"
     ]
    }
   ],
   "source": [
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"efficientnet\",\n",
    "    config= {\n",
    "    \"architecture\": \"efficientnet\",\n",
    "    \"dataset\": \"en_30\",\n",
    "    \"epochs\": \"10\", \n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "model.float()\n",
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in tqdm(train_dataloader):\n",
    "        optim.zero_grad()\n",
    "        audio = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        outputs = model(audio)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        \n",
    "    torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optim.state_dict(),\n",
    "            'loss': loss,\n",
    "            }, f'../model/whisper/epoch_{epoch+1}')\n",
    "        \n",
    "    model.eval()\n",
    "        \n",
    "    for batch in tqdm(dev_dataloader):\n",
    "        audio = batch[0].to(device)\n",
    "        labels = batch[1].to(device)\n",
    "        outputs = model(audio)\n",
    "        \n",
    "        metric.add_batch(predictions=outputs.argmax(-1), references=labels)\n",
    "\n",
    "    wandb.log({\"acc\": metric.compute()['accuracy'], \"loss\": loss})\n",
    "    \n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7012b8f0bd8a8341f73b51b2b438af7e10adf089dc9f82b31de57148a2c65b98"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
